# goflow v1.0.0 - Production-Ready Go Async/IO Toolkit ðŸš€

[![Go Reference](https://pkg.go.dev/badge/github.com/vnykmshr/goflow.svg)](https://pkg.go.dev/github.com/vnykmshr/goflow)
[![Go Report Card](https://goreportcard.com/badge/github.com/vnykmshr/goflow)](https://goreportcard.com/report/github.com/vnykmshr/goflow)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)]()
[![Coverage](https://img.shields.io/badge/coverage-90%2B-brightgreen.svg)]()
[![Version](https://img.shields.io/badge/version-v1.0.0-blue.svg)]()

A production-ready, comprehensive Go library for building robust concurrent applications with rate limiting, scheduling, streaming, and pipeline processing. Features excellent developer experience with helpful error messages, comprehensive documentation, and real-world integration examples.

## ðŸš€ Key Features

### ðŸš¥ Advanced Rate Limiting (`pkg/ratelimit`) - **Production Ready**
- **Token Bucket**: Burst traffic handling with configurable capacity and refill rates
- **Leaky Bucket**: Smooth rate limiting for consistent processing flows
- **Concurrency Limiter**: Resource control with adaptive scaling
- **Distributed Limiting**: Redis-backed coordination for multi-instance deployments
- **Prometheus Metrics**: Full observability with detailed performance metrics

### âš¡ Enterprise Scheduling (`pkg/scheduling`) - **Production Ready**
- **Advanced Worker Pool**: Dynamic scaling, graceful shutdown, comprehensive metrics
- **Sophisticated Scheduler**: Enterprise-grade task scheduling with multiple patterns:
  - **Full Cron Support**: Complete cron expression parsing with timezone handling
  - **Exponential Backoff**: Configurable retry logic with failure handling
  - **Conditional Scheduling**: Execute tasks only when conditions are met
  - **Task Chaining**: Sequential task execution with error handling
  - **Batch Processing**: Parallel task execution with concurrency controls
  - **Adaptive Scheduling**: Dynamic timing based on system load
  - **Time Window Scheduling**: Restrict execution to specific periods
  - **Context Integration**: Sophisticated timeout and cancellation handling
- **Performance Optimizations**: Heap-based scheduling, object pooling, memory compaction
- **Multi-Stage Pipeline**: Complex data processing workflows

### ðŸŒŠ High-Performance Streaming (`pkg/streaming`) - **Production Ready**
- **Stream API**: Functional operations (filter, map, reduce) with parallel processing
- **Async Writer**: Background buffering optimized for high-volume operations
- **Advanced Backpressure**: 4 sophisticated flow control strategies
- **Channel Utilities**: Enhanced channel operations with timeout and cancellation

### ðŸ“Š Comprehensive Observability
- **Prometheus Integration**: Full metrics export for all components
- **Performance Benchmarking**: Extensive benchmarking suite with comparisons
- **Runtime Statistics**: Detailed performance and resource usage metrics
- **Distributed Tracing**: Context propagation for distributed systems

## ðŸš€ Quick Start

```bash
go get github.com/vnykmshr/goflow
```

### Basic Usage with Safe Constructors

```go
package main

import (
    "context"
    "fmt"
    "log"
    "time"
    
    "github.com/vnykmshr/goflow/pkg/ratelimit/bucket"
    "github.com/vnykmshr/goflow/pkg/scheduling/workerpool"
    "github.com/vnykmshr/goflow/pkg/scheduling/scheduler"
)

func main() {
    ctx := context.Background()
    
    // Rate limiting with safe constructors and error handling
    limiter, err := bucket.NewSafe(10, 20) // 10 RPS, burst 20
    if err != nil {
        log.Fatalf("Failed to create rate limiter: %v", err)
    }
    
    // Worker pool with custom configuration
    pool := workerpool.NewWithConfig(workerpool.Config{
        WorkerCount: 5,
        QueueSize:   100,
        TaskTimeout: 30 * time.Second,
    })
    defer func() { <-pool.Shutdown() }()
    
    // Basic scheduler with timezone support
    sched := scheduler.New()
    defer func() { <-sched.Stop() }()
    sched.Start()
    
    // Rate-limited task processing with proper error checking
    if limiter.Allow() {
        task := workerpool.TaskFunc(func(ctx context.Context) error {
            fmt.Println("Processing high-priority request...")
            return nil
        })
        
        // Submit to worker pool with error handling
        if err := pool.Submit(task); err != nil {
            log.Printf("Failed to submit task: %v", err)
            return
        }
        
        // Schedule recurring cleanup job
        cleanupTask := workerpool.TaskFunc(func(ctx context.Context) error {
            fmt.Println("Running cleanup...")
            return nil
        })
        
        if err := sched.ScheduleCron("cleanup", "@daily", cleanupTask); err != nil {
            log.Printf("Failed to schedule cleanup: %v", err)
        }
    }
}
```

### Production Web Service Example

```go
package main

import (
    "context"
    "fmt"
    "log"
    "net/http"
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    
    "github.com/vnykmshr/goflow/pkg/ratelimit/bucket"
    "github.com/vnykmshr/goflow/pkg/ratelimit/concurrency"
    "github.com/vnykmshr/goflow/pkg/scheduling/workerpool"
    "github.com/vnykmshr/goflow/pkg/scheduling/scheduler"
)

func main() {
    // Create rate limiters with proper error handling
    apiLimiter, err := bucket.NewSafe(100, 200) // 100 RPS, burst 200
    if err != nil {
        log.Fatalf("Failed to create API rate limiter: %v", err)
    }
    
    uploadLimiter, err := bucket.NewSafe(10, 50) // 10 RPS, burst 50 for uploads
    if err != nil {
        log.Fatalf("Failed to create upload rate limiter: %v", err)
    }
    
    // Create concurrency limiters for resource protection
    dbLimiter, err := concurrency.NewSafe(20) // Max 20 concurrent DB operations
    if err != nil {
        log.Fatalf("Failed to create DB limiter: %v", err)
    }
    
    // Create worker pool for background tasks
    workers := workerpool.NewWithConfig(workerpool.Config{
        WorkerCount: 10,
        QueueSize:   1000,
        TaskTimeout: 30 * time.Second,
    })
    defer func() { <-workers.Shutdown() }()
    
    // Create scheduler for maintenance tasks
    sched := scheduler.New()
    sched.Start()
    defer func() { <-sched.Stop() }()
    
    // Setup HTTP server with middleware
    mux := http.NewServeMux()
    
    // API endpoints with rate limiting
    mux.HandleFunc("/api/users", withRateLimit(apiLimiter, handleUsers))
    mux.HandleFunc("/api/upload", withRateLimit(uploadLimiter, handleUpload))
    
    // Database operations with concurrency limiting  
    mux.HandleFunc("/api/db/query", withConcurrencyLimit(dbLimiter, handleDB))
    
    // Health and metrics endpoints
    mux.HandleFunc("/health", handleHealth)
    mux.Handle("/metrics", promhttp.Handler())
    
    // Schedule maintenance tasks
    sched.ScheduleRepeating("cleanup", workerpool.TaskFunc(func(ctx context.Context) error {
        log.Println("Running scheduled cleanup")
        return nil
    }), 5*time.Minute)
    
    // Start server
    server := &http.Server{Addr: ":8080", Handler: mux}
    log.Println("Starting server on :8080")
    log.Fatal(server.ListenAndServe())
}

func withRateLimit(limiter bucket.Limiter, handler http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        if !limiter.Allow() {
            http.Error(w, "Rate limit exceeded", http.StatusTooManyRequests)
            return
        }
        handler(w, r)
    }
}
```

## Design Principles

- **Developer-First**: Safe constructors, comprehensive error messages, and excellent documentation
- **Production-Ready**: Enterprise-grade error handling, graceful shutdown, and observability
- **Idiomatic Go**: Uses standard Go concurrency primitives (goroutines, channels, context)
- **Performance**: High-performance and low overhead design with extensive benchmarking
- **Modularity**: Loosely coupled packages for selective imports and dependency management
- **Robustness**: Context-aware operations with comprehensive timeout and cancellation support

## Installation

```bash
go get github.com/vnykmshr/goflow
```

## Documentation & Examples

- [ðŸ“– Getting Started Guide](./docs/GETTING_STARTED.md) - Comprehensive guide for new users
- [ðŸ—ï¸ Production Web Service Example](./examples/web-service/main.go) - Complete integration example
- [ðŸ“š API Documentation](https://pkg.go.dev/github.com/vnykmshr/goflow) - Complete API reference
- [ðŸŽ¯ Examples](./examples/) - Focused examples for each module
- [ðŸ› ï¸ Decision Guide](./docs/DECISION_GUIDE.md) - Help choosing the right components

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for details.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸŽ¯ Implementation Status

### âœ… Production Ready Modules

**ðŸš¥ Advanced Rate Limiting** - *Complete with 91.9-96.6% test coverage*
- [x] **Token Bucket**: Configurable burst capacity and refill rates
- [x] **Leaky Bucket**: Consistent rate smoothing with overflow handling
- [x] **Concurrency Limiter**: Resource control with adaptive scaling
- [x] **Distributed Limiting**: Redis-backed coordination for multi-instance deployments
- [x] **Comprehensive Metrics**: Prometheus integration with detailed performance metrics

**âš¡ Enterprise Task Scheduling** - *Complete with 85-95% test coverage*
- [x] **Advanced Worker Pool**: Dynamic scaling, graceful shutdown, comprehensive metrics
- [x] **Basic Scheduler**: Time-based task execution with interval and one-time scheduling
- [x] **Cron Scheduler**: Full cron expression support with timezone handling
- [x] **Advanced Scheduler**: Enterprise-grade patterns including:
  - [x] Exponential backoff with configurable retry logic
  - [x] Conditional scheduling based on custom conditions
  - [x] Task chaining with error handling and flow control
  - [x] Batch processing with concurrency controls
  - [x] Throttled scheduling with rate limiting
  - [x] Adaptive scheduling based on system load
  - [x] Time window scheduling with day/time restrictions
  - [x] Jittered scheduling to prevent thundering herd
- [x] **Context Integration**: Sophisticated timeout and cancellation handling
- [x] **Performance Optimizations**: Heap-based scheduling, object pooling, memory compaction
- [x] **Multi-Stage Pipeline**: Complex data processing workflows

**ðŸŒŠ High-Performance Streaming** - *Complete with 84.6-95.0% test coverage*
- [x] **Stream API**: Functional operations (filter, map, reduce, collect, etc.)
- [x] **Async Writer**: Background buffering optimized for high-volume operations
- [x] **Advanced Backpressure**: 4 sophisticated flow control strategies:
  - [x] Block strategy for memory-bounded processing
  - [x] Drop strategy for real-time systems
  - [x] Slide strategy for sliding window processing
  - [x] Spill strategy for disk-based overflow
- [x] **Channel Utilities**: Enhanced channel operations with timeout and cancellation

**ðŸ“Š Comprehensive Observability** - *Complete*
- [x] **Prometheus Integration**: Full metrics export for all components
- [x] **Performance Benchmarking**: Extensive benchmarking suite with detailed analysis
- [x] **Runtime Statistics**: Performance and resource usage metrics
- [x] **Distributed Tracing**: Context propagation for distributed systems

### ðŸš€ Architecture Highlights

**Enterprise-Grade Features:**
- **Thread-Safe Operations**: Comprehensive concurrency protection
- **Graceful Shutdown**: Proper resource cleanup and connection draining  
- **Error Recovery**: Sophisticated retry and backoff mechanisms
- **Resource Management**: Automatic scaling and memory optimization
- **Observability**: Full metrics, logging, and tracing integration
- **Production Testing**: Extensive test coverage with realistic scenarios

**Performance Optimizations:**
- **Zero-Copy Operations**: Efficient memory usage patterns
- **Lock-Free Algorithms**: Atomic operations where possible
- **Object Pooling**: Reduced garbage collection pressure
- **Batch Processing**: Optimized throughput for high-volume operations
- **Adaptive Algorithms**: Dynamic adjustment based on runtime conditions

**Distributed Systems Ready:**
- **Context Propagation**: Distributed tracing support
- **Redis Integration**: Coordinated rate limiting across instances  
- **Timezone Handling**: Global scheduling coordination
- **Health Checks**: Built-in monitoring and diagnostics
- **Configuration Management**: Environment-based configuration

### ðŸ“ˆ Performance Benchmarks

- **Scheduler Operations**: ~1,636 ns/op (430 B/op, 6 allocs/op)
- **Cron Scheduling**: ~5,362 ns/op (656 B/op, 6 allocs/op)
- **Expression Parsing**: ~727 ns/op (358 B/op, 13 allocs/op)
- **Rate Limiting**: Sub-microsecond allow/deny decisions
- **Worker Pool**: >100K tasks/second sustained throughput

### ðŸ”„ Continuous Improvements

- [ ] Enhanced streaming connectors (Kafka, gRPC, HTTP/2)
- [ ] Advanced monitoring dashboards and alerting
- [ ] Machine learning-based adaptive algorithms
- [ ] WebAssembly runtime integration
- [ ] Cloud-native deployment patterns